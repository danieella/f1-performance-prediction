{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you lost points on the last checkpoint you can get them back by responding to TA/IA feedback**  \n",
    "\n",
    "Update/change the relevant sections where you lost those points, make sure you respond on GitHub Issues to your TA/IA to call their attention to the changes you made here.\n",
    "\n",
    "Please update your Timeline... no battle plan survives contact with the enemy, so make sure we understand how your plans have changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Sanaya Vakharia\n",
    "- Dhyay Thakrar\n",
    "- Megha Puskur\n",
    "- Daniella"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do track characteristics, driver performance metrics, and weather conditions affect the probability of winning a Formula 1 race?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background and Prior Work\n",
    "\n",
    "## Background & Introduction to Formula 1 Racing\n",
    "Formula 1 racing combines high-speed competition with complex engineering, where predictive analytics play a crucial role in decision-making. Teams utilize vast amounts of data, from tire degradation to driver performance, to optimize race strategies and improve outcomes.\n",
    "\n",
    "## Prior Work\n",
    "1. **Application of Machine Learning**: Recent studies, such as the one documented by Aalto University, have explored the use of machine learning algorithms like Support Vector Machines, Random Forest, and Neural Networks to predict the timing of pit stops in F1 races. This research highlights the importance of various race factors, including tire degradation and weather conditions, in decision-making processes. ([Aaltodoc](https://aaltodoc.aalto.fi/server/api/core/bitstreams/70d5a580-c282-4278-8462-94d061471546/content))\n",
    "\n",
    "2. **Comprehensive Data Analysis Platforms**: Platforms like the one found in the GitHub repository 'f1-analysis' use the FastF1 library to manipulate telemetry and race data for in-depth insights into race performance and strategies. This repository serves as a valuable resource for enthusiasts and analysts looking to perform statistical analyses and create data visualizations based on F1 race data. ([f1-analysis](https://github.com/lalutir/f1-analysis))\n",
    "\n",
    "3. **Industrial Impact of Predictive Analytics**: An overview provided by sites like Penn State's page on predictive analytics in F1 discusses the industrial relevance and financial impact of predictive analytics in the sport. It outlines how teams leverage real-time data from over 300 sensors on each car to make strategic decisions that can alter race results, illustrating the blend of data science with competitive sports to enhance team performance and race strategy. ([F1 and predictive analysis](https://sites.psu.edu/aboutoliviadisanti/2023/11/14/unleashing-the-power-of-data-science-in-formula-1/))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our hypothesis is that track characteristics, driver performance metrics, and weather conditions each significantly influence the probability of winning a Formula 1 race. \n",
    "\n",
    "Track features, such as the layout and corner types, can favor different car setups, potentially creating positive or negative correlations with winning likelihood depending on the car’s strengths. For instance, high-speed tracks may positively correlate with cars optimized for straight-line speed, while technical circuits could benefit those with strong downforce. Driver metrics, including qualifying position, overtaking ability, and consistency, are expected to correlate positively with success, as they reflect a driver’s ability to maximize their position and minimize errors under varying race conditions. Weather conditions add a layer of unpredictability, where rain, temperature, and humidity can shift race dynamics. Rain, for example, may benefit drivers skilled in wet conditions, while high temperatures could challenge teams with poor tire or cooling management, introducing both positive and negative correlations. \n",
    "\n",
    "Previous studies and data analyses, such as those referenced in existing research on machine learning applications in F1 (e.g., the study at Aalto University), suggest that these variables not only affect race strategy but also directly influence race results through their impact on vehicle handling, tire wear, and driver safety. The interaction of these variables is likely complex, given the dynamic and highly conditional nature of racing, where the optimal strategy must continuously adapt to the evolving race conditions.([Aaltodoc](https://aaltodoc.aalto.fi/server/api/core/bitstreams/70d5a580-c282-4278-8462-94d061471546/content))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data overview\n",
    "\n",
    "- Master Dataset: \n",
    "  - Dataset Name: Formula 1 Dataset (1950 - 2023) [Cleaned]\n",
    "  - Link to the dataset: https://www.kaggle.com/datasets/suletanmay/formula-1-dataset-1950-2023-cleaned \n",
    "  - Number of observations: 14 csv files \n",
    "\n",
    "- Dataset 1: \n",
    "  - Dataset Name: Cleaned Circuits\n",
    "  - Link to the dataset: data/cleaned_circuits.csv\n",
    "  - Number of observations: 77 * 5\n",
    "  - Number of variables: 5\n",
    "  \n",
    "- Dataset 2: \n",
    "  - Dataset Name: Cleaned Constructor Results\n",
    "  - Link to the dataset: data/cleaned_constructor_results.csv\n",
    "  - Number of observations: 12290 * 4 \n",
    "  - Number of variables: 4\n",
    "\n",
    "- Dataset 3: \n",
    "  - Dataset Name: Cleaned Constructor Standings\n",
    "  - Link to the dataset: data/cleaned_constructor_standings.csv \n",
    "  - Number of observations: 13051 * 6 \n",
    "  - Number of variables: 6\n",
    "  \n",
    "- Dataset 4: \n",
    "  - Dataset Name: Cleaned Constructors\n",
    "  - Link to the dataset: data/cleaned_constructors.csv \n",
    "  - Number of observations: 211 * 4\n",
    "  - Number of variables: 4\n",
    "  \n",
    "- Dataset 5: \n",
    "  - Dataset Name: Cleaned Driver Standings\n",
    "  - Link to the dataset: data/cleaned_driver_standings.csv\n",
    "  - Number of observations: 34124 * 6\n",
    "  - Number of variables: 6\n",
    "\n",
    "- Dataset 6: \n",
    "  - Dataset Name: Cleaned Drivers\n",
    "  - Link to the dataset: data/cleaned_drivers.csv\n",
    "  - Number of observations: 857 * 7\n",
    "  - Number of variables: 7\n",
    "\n",
    "- Dataset 7: \n",
    "  - Dataset Name: Cleaned Lap Times \n",
    "  - Link to the dataset: data/cleaned_lap_times.csv \n",
    "  - Number of observations: 551742 * 5\n",
    "  - Number of variables: 5\n",
    "\n",
    "- Dataset 8: \n",
    "  - Dataset Name: Cleaned Pit Stops \n",
    "  - Link to the dataset: data/cleaned_pit_stops.csv \n",
    "  - Number of observations: 10089 * 5\n",
    "  - Number of variables: 5\n",
    "  \n",
    "- Dataset 9: \n",
    "  - Dataset Name: Cleaned Qualifying \n",
    "  - Link to the dataset: data/cleaned_qualifying.csv \n",
    "  - Number of observations: 9815 * 9 \n",
    "  - Number of variables: 9\n",
    "\n",
    "- Dataset 10: \n",
    "  - Dataset Name: Cleaned Races \n",
    "  - Link to the dataset: data/cleaned_races.csv \n",
    "  - Number of observations: 1101 * 4 \n",
    "  - Number of variables: 4\n",
    "  \n",
    "- Dataset 11: \n",
    "  - Dataset Name: Cleaned Results\n",
    "  - Link to the dataset: data/cleaned_results.csv\n",
    "  - Number of observations: 14 csv files \n",
    "  - Number of variables:\n",
    "  \n",
    "- Dataset 12: \n",
    "  - Dataset Name: Cleaned Seasons \n",
    "  - Link to the dataset: data/cleaned_seasons.csv \n",
    "  - Number of observations: 74 * 2 \n",
    "  - Number of variables: 2\n",
    "\n",
    "- Dataset 13: \n",
    "  - Dataset Name: Cleaned Sprint Results\n",
    "  - Link to the dataset: data/cleaned_sprint_results.csv \n",
    "  - Number of observations: 180 * 12 \n",
    "  - Number of variables: 12\n",
    "\n",
    "- Dataset 14: \n",
    "  - Dataset Name: Cleaned Status \n",
    "  - Link to the dataset: data/cleaned_status.csv\n",
    "  - Number of observations: 139 * 2\n",
    "  - Number of variables: 2\n",
    "\n",
    "All the datasets are already cleaned, so there are no missing values and everything is formatted correctly (we double checked this). However, there are a lot of unwanted columns which we removed. Moreover, we combined some datasets to make it easier to compute and conduct EDA. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formula 1 Dataset (1950 - 2023) [Cleaned]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in /Users/dhyay/conda/envs/dsc80/lib/python3.8/site-packages (0.2.9)\r\n",
      "Requirement already satisfied: packaging in /Users/dhyay/conda/envs/dsc80/lib/python3.8/site-packages (from kagglehub) (23.1)\r\n",
      "Requirement already satisfied: requests in /Users/dhyay/conda/envs/dsc80/lib/python3.8/site-packages (from kagglehub) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm in /Users/dhyay/conda/envs/dsc80/lib/python3.8/site-packages (from kagglehub) (4.62.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/dhyay/conda/envs/dsc80/lib/python3.8/site-packages (from requests->kagglehub) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/dhyay/conda/envs/dsc80/lib/python3.8/site-packages (from requests->kagglehub) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/dhyay/conda/envs/dsc80/lib/python3.8/site-packages (from requests->kagglehub) (1.26.7)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/dhyay/conda/envs/dsc80/lib/python3.8/site-packages (from requests->kagglehub) (2023.11.17)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import kagglehub\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n"
     ]
    }
   ],
   "source": [
    "path = kagglehub.dataset_download(\"suletanmay/formula-1-dataset-1950-2023-cleaned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuits = pd.read_csv(os.path.join(path, 'cleaned_circuits.csv'))\n",
    "constructor_results = pd.read_csv(os.path.join(path, 'cleaned_constructor_results.csv'))\n",
    "constructor_standings = pd.read_csv(os.path.join(path, 'cleaned_constructor_standings.csv'))\n",
    "constructors = pd.read_csv(os.path.join(path, 'cleaned_constructors.csv'))\n",
    "driver_standings = pd.read_csv(os.path.join(path, 'cleaned_driver_standings.csv'))\n",
    "drivers = pd.read_csv(os.path.join(path, 'cleaned_drivers.csv'))\n",
    "lap_times = pd.read_csv(os.path.join(path, 'cleaned_lap_times.csv'))\n",
    "pit_stops = pd.read_csv(os.path.join(path, 'cleaned_pit_stops.csv'))\n",
    "qualifying = pd.read_csv(os.path.join(path, 'cleaned_qualifying.csv'))\n",
    "races = pd.read_csv(os.path.join(path, 'cleaned_races.csv'))\n",
    "results = pd.read_csv(os.path.join(path, 'cleaned_results.csv'))\n",
    "seasons = pd.read_csv(os.path.join(path, 'cleaned_seasons.csv'))  # if needed\n",
    "sprint_results = pd.read_csv(os.path.join(path, 'cleaned_sprint_results.csv'))  # if needed\n",
    "status = pd.read_csv(os.path.join(path, 'cleaned_status.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuits = circuits[['circuitId', 'circuit_name']]\n",
    "constructors = constructors[['constructorId', 'constructor_name']]\n",
    "drivers = drivers[['driverId', 'driver_code', 'driver_surname']]\n",
    "all_races = races[['raceId', 'year', 'circuitId']].merge(circuits[['circuitId', 'circuit_name']], on = 'circuitId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our team acknowledges the issues related to the unethical use of data. Personal data can endanger the privacy of individuals. Our data will contain information about previous race winners and race conditions, and, although unlikely, our model can be used by the teams in the future to possibly recreate these conditions to influence races."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect everyone in our team to communicate effectively on our text message group.  Our expectations are replies within 2 days on most days and faster replies as we come closer to deadlines. We have decided to have open communication and say everything they feel related to the project and other team members bluntly but politely. If any of us see that someone isn't voicing their opinions because they might be shy, we will try our best to motivate them to speak up. We would prefer the decisions to be unanimous and we will try our best to accommodate if any team members disagrees with the others. If this doesn't work out, we will go with the majority vote because we believe everyone in our group is mature enough to handle disagreements. If a team member is not responding on time and the deadline is extremely close, we will decide to go with a majority vote then too. We have set a schedule with deadlines as proposed below. If someone is struggling with a deliverable, we will try our best to help them and can give them an easier task for that deliverable. They can in return contribute more when something else is due. We are going to publish a list of tasks on a google spreadsheet and update them after each checkpoint from our project timeline. People can tick them off when they are done and we hope to have everything completed before the deadline. We will assign tasks to everyone during our meetings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 11/3  |  1 PM | Complete gathering the data  | Finalize the data and talk about how to go about cleaning it | \n",
    "| 11/10  |  1 PM |  Cleaning and organizing the data | Discuss the cleaned data and start with EDA/split it between team members \n",
    "| 11/16  | 1 PM  | EDA  | Validate the EDAs of everyone and interpret the findings   |\n",
    "| 11/20  | 1 PM  | Come with more insights on the data | Start developing the model   |\n",
    "| 11/25  | 1 PM  | Have an initial model ready | Discuss ways to refine the model |\n",
    "| 11/30  | 1 PM  | Have a refined model | Start creating visualizations |\n",
    "| 12/3  | 1 PM  | Done with visualizations | Start compiling the final project|\n",
    "| 12/6  | 1 PM  | Done with final touch ups | Turn in Final Project |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
